"""
Traitement des nuages de points de Metz
Extraction et reconstruction de b√¢timents ‚Üí Export GLB pour R3F
"""

import numpy as np
import open3d as o3d
import laspy
import json
from pathlib import Path
from typing import List, Dict, Tuple
from dataclasses import dataclass, asdict
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Import optionnel pour scipy (utilis√© pour ConvexHull 2D)
try:
    from scipy.spatial import ConvexHull
    HAS_SCIPY = True
except ImportError:
    HAS_SCIPY = False
    logger.warning("scipy non disponible, utilisation d'une m√©thode alternative pour les enveloppes convexes")


@dataclass
class BuildingMetadata:
    """M√©tadonn√©es d'un b√¢timent"""
    id: str
    num_points: int
    num_planes: int
    bbox_min: List[float]
    bbox_max: List[float]
    center: List[float]
    area_m2: float
    height_m: float


class MetzBuildingProcessor:
    """
    Processeur pour les nuages de points de Metz
    """
    
    def __init__(self, 
                 input_dir: str = None,
                 output_dir: str = None,
                 distance_threshold: float = 0.3):
        """
        Args:
            input_dir: Dossier contenant les fichiers .copc.laz (relatif √† la racine du projet)
            output_dir: Dossier de sortie pour les .glb (relatif √† la racine du projet)
            distance_threshold: Seuil RANSAC en m√®tres
        """
        # Obtenir la racine du projet (un niveau au-dessus du dossier du script)
        project_root = Path(__file__).parent.parent
        
        # Chemins par d√©faut relatifs √† la racine du projet
        if input_dir is None:
            self.input_dir = project_root / "public" / "data" / "metz"
        else:
            # Si le chemin commence par "/", le traiter comme relatif √† la racine du projet
            if input_dir.startswith("/"):
                self.input_dir = project_root / input_dir.lstrip("/")
            else:
                # Sinon, traiter comme chemin absolu ou relatif au r√©pertoire courant
                self.input_dir = Path(input_dir)
        
        if output_dir is None:
            self.output_dir = project_root / "public" / "models"
        else:
            # Si le chemin commence par "/", le traiter comme relatif √† la racine du projet
            if output_dir.startswith("/"):
                self.output_dir = project_root / output_dir.lstrip("/")
            else:
                # Sinon, traiter comme chemin absolu ou relatif au r√©pertoire courant
                self.output_dir = Path(output_dir)
        self.distance_threshold = distance_threshold
        
        # Cr√©er les dossiers de sortie
        self.buildings_dir = self.output_dir / "buildings"
        self.buildings_dir.mkdir(parents=True, exist_ok=True)
        
        self.metadata = []
        
    def find_laz_files(self) -> List[Path]:
        """Trouve tous les fichiers .laz/.copc.laz"""
        laz_files = list(self.input_dir.glob("*.laz")) + \
                    list(self.input_dir.glob("*.copc.laz"))
        
        logger.info(f"Fichiers .laz trouv√©s: {len(laz_files)}")
        for f in laz_files:
            logger.info(f"  - {f.name}")
        
        return laz_files
    
    def load_point_cloud(self, filepath: Path) -> Tuple[np.ndarray, np.ndarray]:
        """Charge un fichier LAZ et retourne points + classifications"""
        logger.info(f"Chargement: {filepath.name}")
        
        las = laspy.read(str(filepath))
        
        # Coordonn√©es XYZ
        points = np.vstack((las.x, las.y, las.z)).transpose()
        
        # Classifications (standard LAS)
        if hasattr(las, 'classification'):
            classifications = np.array(las.classification)
        else:
            classifications = np.zeros(len(points), dtype=np.uint8)
        
        logger.info(f"  Points: {len(points):,}")
        logger.info(f"  Classes: {np.unique(classifications)}")
        
        return points, classifications
    
    def extract_buildings(self, points: np.ndarray, 
                         classifications: np.ndarray) -> np.ndarray:
        """
        Extrait les points classifi√©s comme 'B√¢timent'
        Standard LAS: classe 6 = B√¢timent
        """
        # Classe 6 = B√¢timent selon LAS 1.4
        building_mask = classifications == 6
        building_points = points[building_mask]
        
        logger.info(f"  B√¢timents: {len(building_points):,} points")
        
        return building_points
    
    def segment_buildings_by_proximity(self, 
                                      points: np.ndarray,
                                      eps: float = 2.0,
                                      min_points: int = 100) -> List[np.ndarray]:
        """
        S√©pare les diff√©rents b√¢timents par clustering spatial (DBSCAN)
        
        Args:
            eps: Distance max entre points d'un m√™me cluster (m√®tres)
            min_points: Nombre min de points pour former un b√¢timent
        """
        logger.info("Segmentation des b√¢timents individuels...")
        
        pcd = o3d.geometry.PointCloud()
        pcd.points = o3d.utility.Vector3dVector(points)
        
        # DBSCAN pour identifier les b√¢timents s√©par√©s
        labels = np.array(pcd.cluster_dbscan(
            eps=eps,
            min_points=min_points,
            print_progress=False
        ))
        
        # Extraire chaque cluster
        unique_labels = np.unique(labels)
        buildings = []
        
        for label in unique_labels:
            if label == -1:  # Bruit
                continue
                
            cluster_points = points[labels == label]
            
            if len(cluster_points) >= min_points:
                buildings.append(cluster_points)
        
        logger.info(f"  {len(buildings)} b√¢timents d√©tect√©s")
        
        return buildings
    
    def extract_planes_ransac(self, points: np.ndarray,
                             max_planes: int = 6,
                             min_points: int = 50) -> List[Dict]:
        """Extrait les plans dominants avec RANSAC"""
        
        pcd = o3d.geometry.PointCloud()
        pcd.points = o3d.utility.Vector3dVector(points)
        
        planes = []
        remaining_pcd = pcd
        
        for i in range(max_planes):
            if len(remaining_pcd.points) < min_points:
                break
            
            plane_model, inliers = remaining_pcd.segment_plane(
                distance_threshold=self.distance_threshold,
                ransac_n=3,
                num_iterations=1000
            )
            
            if len(inliers) < min_points:
                break
            
            inlier_cloud = remaining_pcd.select_by_index(inliers)
            inlier_points = np.asarray(inlier_cloud.points)
            
            planes.append({
                'equation': plane_model,
                'points': inlier_points,
                'num_points': len(inliers)
            })
            
            remaining_pcd = remaining_pcd.select_by_index(inliers, invert=True)
        
        return planes
    
    def create_building_mesh(self, points: np.ndarray) -> o3d.geometry.TriangleMesh:
        """
        Cr√©e un mesh 3D √† partir des points d'un b√¢timent
        Utilise une approche hybride: plans RANSAC + enveloppe convexe
        """
        # M√©thode 1: Extraction des plans principaux
        planes = self.extract_planes_ransac(points, max_planes=8)
        
        if len(planes) >= 3:
            # Cr√©er un mesh √† partir des plans
            mesh = self._create_mesh_from_planes(planes)
        else:
            # Fallback: enveloppe convexe
            pcd = o3d.geometry.PointCloud()
            pcd.points = o3d.utility.Vector3dVector(points)
            mesh, _ = pcd.compute_convex_hull()
        
        # Nettoyer le mesh
        mesh.remove_duplicated_vertices()
        mesh.remove_duplicated_triangles()
        mesh.remove_degenerate_triangles()
        
        # Calculer les normales pour un bon rendu
        mesh.compute_vertex_normals()
        
        # Couleur grise pour les b√¢timents
        mesh.paint_uniform_color([0.7, 0.7, 0.75])
        
        return mesh
    
    def _create_mesh_from_planes(self, planes: List[Dict]) -> o3d.geometry.TriangleMesh:
        """
        Cr√©e un mesh √† partir de plans RANSAC en pr√©servant les angles nets
        Chaque plan est converti en une surface plane polygonale
        """
        combined_mesh = o3d.geometry.TriangleMesh()
        
        for plane in planes:
            points = plane['points']
            plane_eq = plane['equation']  # [a, b, c, d] o√π ax + by + cz + d = 0
            
            if len(points) < 3:
                continue
            
            # Cr√©er une surface plane √† partir des points du plan
            plane_mesh = self._create_flat_plane_mesh(points, plane_eq)
            
            if len(plane_mesh.vertices) > 0:
                combined_mesh += plane_mesh
        
        if len(combined_mesh.vertices) == 0:
            # Fallback: utiliser convex hull global mais avec Poisson pour pr√©server les angles
            all_points = np.vstack([p['points'] for p in planes])
            pcd_all = o3d.geometry.PointCloud()
            pcd_all.points = o3d.utility.Vector3dVector(all_points)
            
            # Utiliser Poisson reconstruction avec des param√®tres qui pr√©servent les angles
            try:
                # Calculer les normales d'abord
                pcd_all.estimate_normals()
                pcd_all.normalize_normals()
                
                # Poisson avec depth √©lev√© pour pr√©server les d√©tails
                mesh, _ = o3d.geometry.TriangleMesh.create_from_point_cloud_poisson(
                    pcd_all, depth=9, width=0, scale=1.1, linear_fit=False
                )
                
                # Nettoyer le mesh
                mesh.remove_duplicated_vertices()
                mesh.remove_duplicated_triangles()
                mesh.remove_degenerate_triangles()
                mesh.remove_non_manifold_edges()
                
                combined_mesh = mesh
            except:
                # Dernier recours: convex hull
                combined_mesh, _ = pcd_all.compute_convex_hull()
        
        return combined_mesh
    
    def _create_flat_plane_mesh(self, points: np.ndarray, plane_eq: np.ndarray) -> o3d.geometry.TriangleMesh:
        """
        Cr√©e un mesh plat √† partir des points d'un plan
        Pr√©serve les angles en cr√©ant un polygone 2D puis en le triangulant
        """
        if len(points) < 3:
            return o3d.geometry.TriangleMesh()
        
        # Normal du plan: [a, b, c]
        normal = plane_eq[:3]
        normal = normal / np.linalg.norm(normal)
        
        # Trouver un point sur le plan (point moyen des points)
        center = points.mean(axis=0)
        
        # Cr√©er un syst√®me de coordonn√©es 2D sur le plan
        # Vecteur arbitraire perpendiculaire √† la normale
        if abs(normal[0]) < 0.9:
            u = np.array([1, 0, 0])
        else:
            u = np.array([0, 1, 0])
        
        # Vecteurs de base du plan
        u = u - np.dot(u, normal) * normal
        u = u / np.linalg.norm(u)
        v = np.cross(normal, u)
        
        # Projeter tous les points sur le plan 2D
        points_2d = []
        for pt in points:
            vec = pt - center
            x_2d = np.dot(vec, u)
            y_2d = np.dot(vec, v)
            points_2d.append([x_2d, y_2d])
        
        points_2d = np.array(points_2d)
        
        # Cr√©er un polygone √† partir des points projet√©s
        # Utiliser alpha shape directement sur les points 3D pour pr√©server les limites concaves
        # au lieu d'une enveloppe convexe qui peut d√©passer les limites r√©elles
        try:
            # Utiliser alpha shape directement sur les points 3D du plan
            # Cela pr√©serve mieux les limites concaves et √©vite de d√©passer les limites r√©elles
            pcd_plane = o3d.geometry.PointCloud()
            pcd_plane.points = o3d.utility.Vector3dVector(points)
            
            # Calculer alpha adaptatif bas√© sur la densit√© des points
            # Distance m√©diane entre points voisins
            distances = np.sqrt(np.sum((points[:, np.newaxis, :] - points[np.newaxis, :, :])**2, axis=2))
            non_zero_distances = distances[distances > 0]
            if len(non_zero_distances) > 0:
                median_distance = np.median(non_zero_distances)
                # Alpha adaptatif : plus petit pour pr√©server les d√©tails
                alpha = max(0.3, min(1.5, median_distance * 1.5))
            else:
                alpha = 0.5
            
            try:
                # Essayer alpha shape d'abord (pr√©serve mieux les limites concaves)
                mesh_alpha = o3d.geometry.TriangleMesh.create_from_point_cloud_alpha_shape(
                    pcd_plane, alpha
                )
                
                if len(mesh_alpha.vertices) > 0:
                    # Utiliser directement le mesh de l'alpha shape
                    # Il pr√©serve mieux les limites concaves et ne d√©passe pas les limites r√©elles
                    mesh_alpha.compute_vertex_normals()
                    return mesh_alpha
                else:
                    raise ValueError("Alpha shape vide")
            except:
                # Fallback: utiliser convex hull si alpha shape √©choue
                if HAS_SCIPY:
                    hull_2d = ConvexHull(points_2d)
                    hull_indices = hull_2d.vertices
                    hull_points_3d = points[hull_indices]
                else:
                    hull_3d, _ = pcd_plane.compute_convex_hull()
                    hull_indices = np.unique(np.asarray(hull_3d.triangles).flatten())
                    hull_points_3d = points[hull_indices]
                
                # Cr√©er un mesh √† partir du polygone convexe
                mesh = o3d.geometry.TriangleMesh()
                mesh.vertices = o3d.utility.Vector3dVector(hull_points_3d)
                
                # Trianguler le polygone convexe (fan triangulation)
                num_verts = len(hull_points_3d)
                if num_verts >= 3:
                    triangles = []
                    for i in range(1, num_verts - 1):
                        triangles.append([0, i, i + 1])
                    mesh.triangles = o3d.utility.Vector3iVector(triangles)
                    
                    # Calculer les normales (toutes pointent vers la normale du plan)
                    mesh.vertex_normals = o3d.utility.Vector3dVector(
                        [normal] * num_verts
                    )
                
                return mesh
            
        except Exception as e:
            logger.warning(f"Erreur cr√©ation mesh plan: {e}")
            # Fallback: utiliser alpha shape avec alpha tr√®s petit pour pr√©server les angles
            pcd = o3d.geometry.PointCloud()
            pcd.points = o3d.utility.Vector3dVector(points)
            
            try:
                # Alpha tr√®s petit pour pr√©server les angles
                mesh = o3d.geometry.TriangleMesh.create_from_point_cloud_alpha_shape(
                    pcd, alpha=0.1
                )
                return mesh
            except:
                return o3d.geometry.TriangleMesh()
    
    def compute_building_metadata(self, 
                                  building_id: str,
                                  points: np.ndarray,
                                  planes: List[Dict]) -> BuildingMetadata:
        """Calcule les m√©tadonn√©es d'un b√¢timent"""
        
        bbox_min = points.min(axis=0).tolist()
        bbox_max = points.max(axis=0).tolist()
        center = points.mean(axis=0).tolist()
        
        # Estimation de la surface au sol (emprise)
        footprint_points = points[points[:, 2] < np.percentile(points[:, 2], 20)]
        if len(footprint_points) > 0:
            x_range = footprint_points[:, 0].max() - footprint_points[:, 0].min()
            y_range = footprint_points[:, 1].max() - footprint_points[:, 1].min()
            area_m2 = float(x_range * y_range)
        else:
            area_m2 = 0.0
        
        # Hauteur
        height_m = float(bbox_max[2] - bbox_min[2])
        
        return BuildingMetadata(
            id=building_id,
            num_points=len(points),
            num_planes=len(planes),
            bbox_min=bbox_min,
            bbox_max=bbox_max,
            center=center,
            area_m2=area_m2,
            height_m=height_m
        )
    
    def export_to_glb(self, mesh: o3d.geometry.TriangleMesh, 
                     output_path: Path):
        """Exporte un mesh au format GLB (optimis√© pour R3F)"""
        # Open3D peut exporter en GLB/GLTF
        try:
            o3d.io.write_triangle_mesh(
                str(output_path),
                mesh,
                write_ascii=False,
                compressed=True
            )
            logger.info(f"  Export√©: {output_path.name}")
        except Exception as e:
            logger.error(f"  Erreur export GLB: {e}")
            # Fallback: export en OBJ
            obj_path = output_path.with_suffix('.obj')
            o3d.io.write_triangle_mesh(str(obj_path), mesh)
            logger.info(f"  Export√© (OBJ): {obj_path.name}")
    
    def process_all(self):
        """Traite tous les fichiers .laz du dossier"""
        
        logger.info("=" * 70)
        logger.info("TRAITEMENT DES NUAGES DE POINTS DE METZ")
        logger.info("=" * 70)
        
        laz_files = self.find_laz_files()
        
        if not laz_files:
            logger.warning("Aucun fichier .laz trouv√©!")
            return
        
        all_buildings = []
        building_counter = 0
        
        # Traiter chaque fichier LAZ
        for laz_file in laz_files:
            logger.info(f"\n{'=' * 70}")
            logger.info(f"Fichier: {laz_file.name}")
            logger.info(f"{'=' * 70}")
            
            # Charger le nuage de points
            points, classifications = self.load_point_cloud(laz_file)
            
            # Extraire les b√¢timents
            building_points = self.extract_buildings(points, classifications)
            
            if len(building_points) == 0:
                logger.warning("  Aucun point de b√¢timent trouv√©")
                continue
            
            # Segmenter les b√¢timents individuels
            buildings = self.segment_buildings_by_proximity(building_points)
            
            # Traiter chaque b√¢timent
            for i, bldg_points in enumerate(buildings):
                building_counter += 1
                building_id = f"building_{building_counter:04d}"
                
                logger.info(f"\n  B√¢timent {building_id}: {len(bldg_points):,} points")
                
                # Extraire les plans
                planes = self.extract_planes_ransac(bldg_points)
                logger.info(f"    Plans d√©tect√©s: {len(planes)}")
                
                # Cr√©er le mesh
                mesh = self.create_building_mesh(bldg_points)
                logger.info(f"    Mesh: {len(mesh.vertices)} vertices, {len(mesh.triangles)} triangles")
                
                # Calculer m√©tadonn√©es
                metadata = self.compute_building_metadata(
                    building_id, 
                    bldg_points,
                    planes
                )
                self.metadata.append(metadata)
                
                # Exporter en GLB
                output_path = self.buildings_dir / f"{building_id}.glb"
                self.export_to_glb(mesh, output_path)
                
                all_buildings.append(mesh)
        
        logger.info(f"\n{'=' * 70}")
        logger.info(f"R√âSUM√â")
        logger.info(f"{'=' * 70}")
        logger.info(f"B√¢timents trait√©s: {building_counter}")
        logger.info(f"Fichiers .glb g√©n√©r√©s: {len(all_buildings)}")
        
        # Cr√©er un fichier merged avec tous les b√¢timents
        if all_buildings:
            self._create_merged_model(all_buildings)
        
        # Sauvegarder les m√©tadonn√©es
        self._save_metadata()
    
    def _create_merged_model(self, meshes: List[o3d.geometry.TriangleMesh]):
        """
        Cr√©e un fichier GLB unique avec tous les b√¢timents
        Pr√©serve les espaces entre les b√¢timents en √©vitant les intersections
        """
        logger.info("\nCr√©ation du mod√®le merged...")
        
        combined = o3d.geometry.TriangleMesh()
        
        for i, mesh in enumerate(meshes):
            # Nettoyer chaque mesh individuel avant la fusion
            mesh.remove_duplicated_vertices()
            mesh.remove_duplicated_triangles()
            mesh.remove_degenerate_triangles()
            mesh.remove_non_manifold_edges()
            
            # S'assurer que le mesh est orient√© correctement
            mesh.compute_vertex_normals()
            mesh.normalize_normals()
            
            # Ajouter le mesh au mod√®le combin√©
            # L'op√©ration += pr√©serve les meshes s√©par√©s sans cr√©er d'intersections
            combined += mesh
            
            if (i + 1) % 100 == 0:
                logger.info(f"  Trait√© {i + 1}/{len(meshes)} b√¢timents...")
        
        # Nettoyage final du mesh combin√©
        logger.info("Nettoyage du mesh combin√©...")
        combined.remove_duplicated_vertices()
        combined.remove_duplicated_triangles()
        combined.remove_degenerate_triangles()
        combined.remove_non_manifold_edges()
        
        # Recalculer les normales pour un bon rendu
        combined.compute_vertex_normals()
        
        output_path = self.output_dir / "buildings_merged.glb"
        self.export_to_glb(combined, output_path)
        
        logger.info(f"Mod√®le merged: {len(combined.vertices):,} vertices, {len(combined.triangles):,} triangles")
    
    def _save_metadata(self):
        """Sauvegarde les m√©tadonn√©es en JSON"""
        metadata_path = self.output_dir / "metadata.json"
        
        data = {
            'buildings': [asdict(m) for m in self.metadata],
            'total_buildings': len(self.metadata),
            'processing_params': {
                'distance_threshold': self.distance_threshold,
                'input_dir': str(self.input_dir),
                'output_dir': str(self.output_dir)
            }
        }
        
        with open(metadata_path, 'w', encoding='utf-8') as f:
            json.dump(data, f, indent=2, ensure_ascii=False)
        
        logger.info(f"\nM√©tadonn√©es sauvegard√©es: {metadata_path}")


def main():
    """Point d'entr√©e principal"""
    
    processor = MetzBuildingProcessor(
        input_dir=None,                      # Utilise public/data/metz par d√©faut
        output_dir=None,                     # Utilise public/models par d√©faut
        distance_threshold=0.3               # 30cm de tol√©rance RANSAC
    )
    
    processor.process_all()
    
    logger.info("\n" + "=" * 70)
    logger.info("TRAITEMENT TERMIN√â!")
    logger.info("=" * 70)
    logger.info("\nFichiers g√©n√©r√©s:")
    logger.info(f"  üìÅ {processor.output_dir / 'buildings'}")
    logger.info("     ‚îú‚îÄ‚îÄ building_0001.glb")
    logger.info("     ‚îú‚îÄ‚îÄ building_0002.glb")
    logger.info("     ‚îî‚îÄ‚îÄ ...")
    logger.info(f"  üìÑ {processor.output_dir / 'buildings_merged.glb'}")
    logger.info(f"  üìÑ {processor.output_dir / 'metadata.json'}")
    logger.info("\nVous pouvez maintenant charger ces fichiers dans R3F!")


if __name__ == "__main__":
    main()